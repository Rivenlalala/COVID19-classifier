{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "One-Script-to-Rule-Them-All.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rivenlalala/COVID19-classifier/blob/master/One_Script_to_Rule_Them_All.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTL6T4MlXGp9",
        "colab_type": "code",
        "outputId": "f176af04-8a0d-41b4-a5bf-3812416ba914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/Rivenlalala/COVID19-classifier"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'COVID19-classifier'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 2632 (delta 4), reused 8 (delta 2), pack-reused 2621\u001b[K\n",
            "Receiving objects: 100% (2632/2632), 404.96 MiB | 12.52 MiB/s, done.\n",
            "Resolving deltas: 100% (141/141), done.\n",
            "Checking out files: 100% (2594/2594), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqlkGUSTRRUG",
        "colab_type": "code",
        "outputId": "720bc492-71ae-4ff5-9546-3f396f7631dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd COVID19-classifier"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/COVID19-classifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4_MzeyVGDYn",
        "colab_type": "code",
        "outputId": "19d77154-9d22-485d-f150-c9bfd7945009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking out files:  83% (1457/1753)   \rChecking out files:  84% (1473/1753)   \rChecking out files:  85% (1491/1753)   \rChecking out files:  86% (1508/1753)   \rChecking out files:  87% (1526/1753)   \rChecking out files:  88% (1543/1753)   \rChecking out files:  89% (1561/1753)   \rChecking out files:  90% (1578/1753)   \rChecking out files:  91% (1596/1753)   \rChecking out files:  92% (1613/1753)   \rChecking out files:  93% (1631/1753)   \rChecking out files:  94% (1648/1753)   \rChecking out files:  95% (1666/1753)   \rChecking out files:  96% (1683/1753)   \rChecking out files:  97% (1701/1753)   \rChecking out files:  98% (1718/1753)   \rChecking out files:  99% (1736/1753)   \rChecking out files: 100% (1753/1753)   \rChecking out files: 100% (1753/1753), done.\n",
            "Note: checking out 'origin/test'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 2c284d6 Merge branch 'test' of https://github.com/Rivenlalala/COVID19-classifier into test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhJGqdVoeGlO",
        "colab_type": "code",
        "outputId": "545e19d2-be0a-45ad-96b0-6d6e8c1afa23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torchvision.utils import *\n",
        "from torchvision import models\n",
        "from models import *\n",
        "from utils import *\n",
        "import cv2\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "\n",
        "for i in range(2):\n",
        "    data = CustomCompose([transforms.RandomHorizontalFlip(),\n",
        "                        transforms.RandomRotation(10),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                                    std=[0.5, 0.5, 0.5])])\n",
        "    test = CustomCompose([transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                                std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "\n",
        "    dataset_unnormalized = CustomFolder(root='dataset/train_s', transform=data)\n",
        "    dataset_normalized = CustomFolder(root='dataset/train_sn', transform=data)\n",
        "    testset_unnormalized = CustomFolder(root='dataset/test_s', transform=test)\n",
        "    testset_normalized = CustomFolder(root='dataset/test_sn', transform=test)\n",
        "    validate_unnormalized = CustomFolder(root='dataset/train_s', transform=test)\n",
        "    validate_normalized = CustomFolder(root='dataset/train_sn', transform=test)\n",
        "\n",
        "    DN = DenseNet121().cuda()\n",
        "    training(DN, 100,  dataset_unnormalized, validate_unnormalized, testset_unnormalized, \"DN-u-c.pth\")\n",
        "    VGG = VGG16().cuda()\n",
        "    training(VGG, 100, dataset_unnormalized, validate_unnormalized, testset_unnormalized, \"vgg-u-c.pth\")\n",
        "\n",
        "    DN = DenseNet121().cuda()\n",
        "    training(DN, 100,  dataset_normalized, validate_normalized, testset_normalized, \"DN-n-c.pth\")\n",
        "    VGG = VGG16().cuda()\n",
        "    training(VGG, 100, dataset_normalized, validate_normalized, testset_normalized, \"vgg-n-c.pth\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 14:  13%|█▎        | 13/100 [02:00<13:24,  9.25s/it, loss=0.215]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qKnRiNvkku",
        "colab_type": "code",
        "outputId": "74be431e-8cf7-4203-fa58-f88679016564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "for i in range(2):\n",
        "    data = CustomCompose([transforms.RandomHorizontalFlip(),\n",
        "                        transforms.RandomRotation(10),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                                    std=[0.5, 0.5, 0.5])])\n",
        "    test = CustomCompose([transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                            std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "\n",
        "    dataset_unnormalized = CustomFolder(root='dataset/train', transform=data)\n",
        "    dataset_normalized = CustomFolder(root='dataset/train_n', transform=data)\n",
        "    testset_unnormalized = CustomFolder(root='dataset/test', transform=test)\n",
        "    testset_normalized = CustomFolder(root='dataset/test_n', transform=test)\n",
        "    validate_unnormalized = CustomFolder(root='dataset/train', transform=test)\n",
        "    validate_normalized = CustomFolder(root='dataset/train_n', transform=test)\n",
        "\n",
        "    DN = DenseNet121().cuda()\n",
        "    training(DN, 100,  dataset_unnormalized, validate_unnormalized, testset_unnormalized, \"DN-u-n.pth\")\n",
        "    VGG = VGG16().cuda()\n",
        "    training(VGG, 100, dataset_unnormalized, validate_unnormalized, testset_unnormalized, \"vgg-u-n.pth\")\n",
        "\n",
        "    DN = DenseNet121().cuda()\n",
        "    training(DN, 100,  dataset_normalized, validate_normalized, testset_normalized, \"DN-n-n.pth\")\n",
        "    VGG = VGG16().cuda()\n",
        "    training(VGG, 100, dataset_normalized, validate_normalized, testset_normalized, \"vgg-n-n.pth\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [11:54<00:00,  7.15s/it, loss=0.0944]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-u-n.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 114  TN: 387  FP: 1  FN: 0\n",
            "Testing Acc: \n",
            "TP: 18  TN: 86  FP: 5  FN: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [12:16<00:00,  7.37s/it, loss=0.408]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-u-n.pth\n",
            "Training Acc: \n",
            "TP: 114  TN: 386  FP: 2  FN: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing Acc: \n",
            "TP: 28  TN: 80  FP: 11  FN: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [11:42<00:00,  7.03s/it, loss=0.0943]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-n-n.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 113  TN: 387  FP: 1  FN: 1\n",
            "Testing Acc: \n",
            "TP: 11  TN: 83  FP: 8  FN: 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [12:14<00:00,  7.35s/it, loss=0.422]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-n-n.pth\n",
            "Training Acc: \n",
            "TP: 89  TN: 387  FP: 1  FN: 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing Acc: \n",
            "TP: 17  TN: 83  FP: 8  FN: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [11:46<00:00,  7.06s/it, loss=0.0578]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-u-n.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 113  TN: 387  FP: 1  FN: 1\n",
            "Testing Acc: \n",
            "TP: 22  TN: 83  FP: 8  FN: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [12:16<00:00,  7.37s/it, loss=0.419]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-u-n.pth\n",
            "Training Acc: \n",
            "TP: 110  TN: 387  FP: 1  FN: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing Acc: \n",
            "TP: 25  TN: 83  FP: 8  FN: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [11:45<00:00,  7.06s/it, loss=0.0435]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-n-n.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 113  TN: 388  FP: 0  FN: 1\n",
            "Testing Acc: \n",
            "TP: 13  TN: 86  FP: 5  FN: 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [12:17<00:00,  7.37s/it, loss=0.415]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-n-n.pth\n",
            "Training Acc: \n",
            "TP: 102  TN: 386  FP: 2  FN: 12\n",
            "Testing Acc: \n",
            "TP: 20  TN: 81  FP: 10  FN: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okiBNmxmfHEX",
        "colab_type": "code",
        "outputId": "f20792be-8ef5-43d3-a43d-85bc7d27660a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torchvision.utils import *\n",
        "from torchvision import models\n",
        "from models import *\n",
        "from utils import *\n",
        "import cv2\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "for i in range(2):\n",
        "    all_data = CustomFolder(root='dataset/train_s', transform=CustomCompose([]))\n",
        "    all_data_norm = CustomFolder(root='dataset/train_sn', transform=CustomCompose([]))\n",
        "\n",
        "    minority = np.array([np.array(image[0], dtype=\"float\") for image in all_data if image[1]==0])\n",
        "    minority_norm = np.array([np.array(image[0], dtype=\"float\") for image in all_data_norm if image[1]==0])\n",
        "\n",
        "    augment = CustomFolder(root=\"dataset/train_s\", transform=CustomCompose([Smote(minority, 5)]))\n",
        "    augment_norm = CustomFolder(root=\"dataset/train_sn\", transform=CustomCompose([Smote(minority, 5)]))\n",
        "\n",
        "    augmented1 = [img for img in augment if img[1] == 0]\n",
        "    augmented_norm1 = [img for img in augment_norm if img[1] == 0]\n",
        "    augmented2 = [img for img in augment if img[1] == 0]\n",
        "    augmented_norm2 = [img for img in augment_norm if img[1] == 0]\n",
        "\n",
        "    data = CustomCompose([transforms.RandomHorizontalFlip(),\n",
        "                        transforms.RandomRotation(10),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                            std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "    dataset_unnormalized = CustomDataset((all_data, augmented1, augmented2), transform=data)\n",
        "    dataset_normalized = CustomDataset((all_data_norm, augmented_norm1, augmented_norm2), transform=data)\n",
        "\n",
        "    test = CustomCompose([transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                            std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "    testset_unnormalized = CustomFolder(root='dataset/test_s', transform=test)\n",
        "    testset_normalized = CustomFolder(root='dataset/test_sn', transform=test)\n",
        "    validate_unnormalized = CustomFolder(root='dataset/train_s', transform=test)\n",
        "    validate_normalized = CustomFolder(root='dataset/train_sn', transform=test)\n",
        "\n",
        "    DN = DenseNet121().cuda()\n",
        "    training(DN, 100, dataset_unnormalized, validate_unnormalized, testset_unnormalized, \"DN-u-smote.pth\")\n",
        "    VGG = VGG16().cuda()\n",
        "    training(VGG, 100, dataset_unnormalized, validate_unnormalized, testset_unnormalized, \"vgg-u-smote.pth\")\n",
        "\n",
        "    DN = DenseNet121().cuda()\n",
        "    training(DN, 100, dataset_normalized, validate_normalized, testset_normalized, \"DN-n-smote.pth\")\n",
        "    VGG = VGG16().cuda()\n",
        "    training(VGG, 100, dataset_normalized, validate_normalized, testset_normalized, \"vgg-n-smote.pth\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [15:38<00:00,  9.38s/it, loss=0.0691]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-u-smote.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 342  TN: 349  FP: 1  FN: 0\n",
            "Testing Acc: \n",
            "TP: 28  TN: 78  FP: 2  FN: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [16:37<00:00,  9.98s/it, loss=0.295]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-u-smote.pth\n",
            "Training Acc: \n",
            "TP: 342  TN: 350  FP: 0  FN: 0\n",
            "Testing Acc: \n",
            "TP: 26  TN: 80  FP: 0  FN: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [16:24<00:00,  9.85s/it, loss=0.0336]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-n-smote.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 342  TN: 350  FP: 0  FN: 0\n",
            "Testing Acc: \n",
            "TP: 23  TN: 77  FP: 3  FN: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [16:38<00:00,  9.99s/it, loss=0.308]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-n-smote.pth\n",
            "Training Acc: \n",
            "TP: 342  TN: 349  FP: 1  FN: 0\n",
            "Testing Acc: \n",
            "TP: 21  TN: 75  FP: 5  FN: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [15:43<00:00,  9.43s/it, loss=0.062]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-u-smote.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 342  TN: 350  FP: 0  FN: 0\n",
            "Testing Acc: \n",
            "TP: 22  TN: 80  FP: 0  FN: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [16:37<00:00,  9.97s/it, loss=0.317]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-u-smote.pth\n",
            "Training Acc: \n",
            "TP: 342  TN: 349  FP: 1  FN: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing Acc: \n",
            "TP: 30  TN: 80  FP: 0  FN: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [15:49<00:00,  9.49s/it, loss=0.0573]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-n-smote.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 342  TN: 348  FP: 2  FN: 0\n",
            "Testing Acc: \n",
            "TP: 23  TN: 75  FP: 5  FN: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [16:39<00:00,  9.99s/it, loss=0.289]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-n-smote.pth\n",
            "Training Acc: \n",
            "TP: 338  TN: 349  FP: 1  FN: 4\n",
            "Testing Acc: \n",
            "TP: 25  TN: 80  FP: 0  FN: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHwfc0Gdz1Hp",
        "colab_type": "code",
        "outputId": "1279cf01-f6c0-4fb9-d844-0041bf02940c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torchvision.utils import *\n",
        "from torchvision import models\n",
        "from models import *\n",
        "from utils import *\n",
        "import cv2\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "for i in range(2):\n",
        "    all_data = CustomFolder(root='dataset/train_s', transform=CustomCompose([]))\n",
        "    all_data_norm = CustomFolder(root='dataset/train_sn', transform=CustomCompose([]))\n",
        "\n",
        "    raw = np.array([np.array(image[0], dtype=\"float\") for image in all_data])\n",
        "    raw_norm = np.array([np.array(image[0], dtype=\"float\") for image in all_data_norm])\n",
        "\n",
        "    augment = CustomFolder(root=\"dataset/train_s\", transform=CustomCompose([SampleParing(raw, minority_only=False)]))\n",
        "    augment_norm = CustomFolder(root=\"dataset/train_sn\", transform=CustomCompose([SampleParing(raw_norm, minority_only=False)]))\n",
        "\n",
        "    augmented1 = [img for img in augment]\n",
        "    augmented_norm1 = [img for img in augment_norm]\n",
        "    augmented2 = [img for img in augment]\n",
        "    augmented_norm2 = [img for img in augment_norm]\n",
        "\n",
        "    data = CustomCompose([transforms.RandomHorizontalFlip(),\n",
        "                        transforms.RandomRotation(10),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                            std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "    dataset_unnormalized = CustomDataset((all_data, augmented1, augmented2), transform=data)\n",
        "    dataset_normalized = CustomDataset((all_data_norm, augmented_norm1, augmented_norm2), transform=data)\n",
        "\n",
        "    test = CustomCompose([transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                            std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "    testset_unnormalized = CustomFolder(root='dataset/test_s', transform=test)\n",
        "    testset_normalized = CustomFolder(root='dataset/test_sn', transform=test)\n",
        "    validate_unnormalized = CustomFolder(root='dataset/train_s', transform=test)\n",
        "    validate_normalized = CustomFolder(root='dataset/train_sn', transform=test)\n",
        "\n",
        "    DN = DenseNet121().cuda()\n",
        "    training(DN, 100,  dataset_unnormalized, validate_unnormalized, testset_unnormalized, \"DN-u-sp.pth\")\n",
        "    VGG = VGG16().cuda()\n",
        "    training(VGG, 100, dataset_unnormalized, validate_unnormalized, testset_unnormalized, \"vgg-u-sp.pth\")\n",
        "\n",
        "    DN = DenseNet121().cuda()\n",
        "    training(DN, 100,  dataset_normalized, validate_normalized, testset_normalized, \"DN-n-sp.pth\")\n",
        "    VGG = VGG16().cuda()\n",
        "    training(VGG, 100, dataset_normalized, validate_normalized, testset_normalized, \"vgg-n-sp.pth\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [30:37<00:00, 18.37s/it, loss=0.123]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-u-sp.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 332  TN: 1015  FP: 35  FN: 10\n",
            "Testing Acc: \n",
            "TP: 27  TN: 77  FP: 3  FN: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [32:44<00:00, 19.64s/it, loss=0.372]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-u-sp.pth\n",
            "Training Acc: \n",
            "TP: 312  TN: 987  FP: 63  FN: 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing Acc: \n",
            "TP: 29  TN: 79  FP: 1  FN: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [30:18<00:00, 18.18s/it, loss=0.101]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-n-sp.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 338  TN: 1036  FP: 14  FN: 4\n",
            "Testing Acc: \n",
            "TP: 22  TN: 71  FP: 9  FN: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [32:39<00:00, 19.60s/it, loss=0.37]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-n-sp.pth\n",
            "Training Acc: \n",
            "TP: 316  TN: 1009  FP: 41  FN: 26\n",
            "Testing Acc: \n",
            "TP: 21  TN: 79  FP: 1  FN: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [30:18<00:00, 18.18s/it, loss=0.145]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-u-sp.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 333  TN: 1022  FP: 28  FN: 9\n",
            "Testing Acc: \n",
            "TP: 27  TN: 79  FP: 1  FN: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [32:45<00:00, 19.66s/it, loss=0.377]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-u-sp.pth\n",
            "Training Acc: \n",
            "TP: 297  TN: 991  FP: 59  FN: 45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing Acc: \n",
            "TP: 24  TN: 80  FP: 0  FN: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [30:36<00:00, 18.36s/it, loss=0.0865]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-n-sp.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 342  TN: 1019  FP: 31  FN: 0\n",
            "Testing Acc: \n",
            "TP: 22  TN: 74  FP: 6  FN: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [32:44<00:00, 19.65s/it, loss=0.348]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-n-sp.pth\n",
            "Training Acc: \n",
            "TP: 327  TN: 1026  FP: 24  FN: 15\n",
            "Testing Acc: \n",
            "TP: 20  TN: 77  FP: 3  FN: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORan1Qa62LHj",
        "colab_type": "code",
        "outputId": "caed559d-9ba4-4c44-f89f-2dc3dba0884d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torchvision.utils import *\n",
        "from torchvision import models\n",
        "from models import *\n",
        "from utils import *\n",
        "import cv2\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "for i in range(2):\n",
        "    all_data = CustomFolder(root='dataset/train_s', transform=CustomCompose([]))\n",
        "    all_data_norm = CustomFolder(root='dataset/train_sn', transform=CustomCompose([]))\n",
        "\n",
        "    augment = CustomFolder(root=\"dataset/train_s\", transform=CustomCompose([RICAP(all_data)]))\n",
        "    augment_norm = CustomFolder(root=\"dataset/train_sn\", transform=CustomCompose([RICAP(all_data_norm)]))\n",
        "\n",
        "    augmented1 = [img for img in augment]\n",
        "    augmented_norm1 = [img for img in augment_norm]\n",
        "    augmented2 = [img for img in augment]\n",
        "    augmented_norm2 = [img for img in augment_norm]\n",
        "\n",
        "    data = CustomCompose([transforms.RandomHorizontalFlip(),\n",
        "                        transforms.RandomRotation(10),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                            std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "    dataset_unnormalized = CustomDataset((all_data, augmented1, augmented2), transform=data)\n",
        "    dataset_normalized = CustomDataset((all_data_norm, augmented_norm1, augmented_norm2), transform=data)\n",
        "\n",
        "    test = CustomCompose([transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                            std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "    testset_unnormalized = CustomFolder(root='dataset/test_s', transform=test)\n",
        "    testset_normalized = CustomFolder(root='dataset/test_sn', transform=test)\n",
        "    validate_unnormalized = CustomFolder(root='dataset/train_s', transform=test)\n",
        "    validate_normalized = CustomFolder(root='dataset/train_sn', transform=test)\n",
        "\n",
        "    DN = DenseNet121().cuda()\n",
        "    training(DN, 100,  dataset_unnormalized, validate_unnormalized, testset_unnormalized, \"DN-u-R.pth\")\n",
        "    VGG = VGG16().cuda()\n",
        "    training(VGG, 100, dataset_unnormalized, validate_unnormalized, testset_unnormalized, \"vgg-u-R.pth\")\n",
        "\n",
        "    DN = DenseNet121().cuda()\n",
        "    training(DN, 100,  dataset_normalized, validate_normalized, testset_normalized, \"DN-n-R.pth\")\n",
        "    VGG = VGG16().cuda()\n",
        "    training(VGG, 100, dataset_normalized, validate_normalized, testset_normalized, \"vgg-n-R.pth\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [31:22<00:00, 18.83s/it, loss=0.264]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-u-R.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 119  TN: 623  FP: 231  FN: 419\n",
            "Testing Acc: \n",
            "TP: 27  TN: 79  FP: 1  FN: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [32:44<00:00, 19.65s/it, loss=0.393]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-u-R.pth\n",
            "Training Acc: \n",
            "TP: 119  TN: 625  FP: 275  FN: 373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing Acc: \n",
            "TP: 28  TN: 80  FP: 0  FN: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [30:12<00:00, 18.13s/it, loss=0.236]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-n-R.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 116  TN: 610  FP: 216  FN: 450\n",
            "Testing Acc: \n",
            "TP: 23  TN: 79  FP: 1  FN: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [32:40<00:00, 19.60s/it, loss=0.385]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-n-R.pth\n",
            "Training Acc: \n",
            "TP: 116  TN: 607  FP: 251  FN: 418\n",
            "Testing Acc: \n",
            "TP: 30  TN: 79  FP: 1  FN: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [30:04<00:00, 18.04s/it, loss=0.266]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-u-R.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 114  TN: 605  FP: 221  FN: 452\n",
            "Testing Acc: \n",
            "TP: 28  TN: 79  FP: 1  FN: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [32:39<00:00, 19.60s/it, loss=0.394]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "vgg-u-R.pth\n",
            "Training Acc: \n",
            "TP: 114  TN: 610  FP: 231  FN: 437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing Acc: \n",
            "TP: 27  TN: 79  FP: 1  FN: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 100: 100%|██████████| 100/100 [30:14<00:00, 18.14s/it, loss=0.234]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "DN-n-R.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Acc: \n",
            "TP: 115  TN: 654  FP: 165  FN: 458\n",
            "Testing Acc: \n",
            "TP: 19  TN: 79  FP: 1  FN: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH 84:  83%|████████▎ | 83/100 [26:50<05:30, 19.44s/it, loss=0.41]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ikmuVwm-r7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "from utils import *\n",
        "from models import *\n",
        "import cv2\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "for i in range(2):\n",
        "    all_data = CustomFolder(root='dataset/train_s', transform=CustomCompose([]))\n",
        "    all_data_norm = CustomFolder(root='dataset/train_sn', transform=CustomCompose([]))\n",
        "\n",
        "    minority = np.array([np.array(image[0], dtype=\"float\") for image in all_data if image[1]==0])\n",
        "    minority_norm = np.array([np.array(image[0], dtype=\"float\") for image in all_data_norm if image[1]==0])\n",
        "\n",
        "    augment = CustomFolder(root=\"dataset/train_s\", transform=CustomCompose([Majority(minority)]))\n",
        "    augment_norm = CustomFolder(root=\"dataset/train_sn\", transform=CustomCompose([Majority(minority_norm)]))\n",
        "\n",
        "    augmented1 = [img for img in augment if img[1] == 0]\n",
        "    augmented_norm1 = [img for img in augment_norm if img[1] == 0]\n",
        "\n",
        "    data = CustomCompose([transforms.RandomHorizontalFlip(),\n",
        "                        transforms.RandomRotation(10),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                            std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "    dataset_unnormalized = CustomDataset((all_data, augmented1), transform=data)\n",
        "    dataset_normalized = CustomDataset((all_data_norm, augmented_norm1), transform=data)\n",
        "\n",
        "    test = CustomCompose([transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                            std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "    testset_unnormalized = CustomFolder(root='dataset/test_s', transform=test)\n",
        "    testset_normalized = CustomFolder(root='dataset/test_sn', transform=test)\n",
        "    validate_unnormalized = CustomFolder(root='dataset/train_s', transform=test)\n",
        "    validate_normalized = CustomFolder(root='dataset/train_sn', transform=test)\n",
        "\n",
        "    DN = DenseNet121().cuda()\n",
        "    training(DN, 100,  dataset_unnormalized, validate_unnormalized, testset_unnormalized, \"DN-u-M.pth\")\n",
        "    VGG = VGG16().cuda()\n",
        "    training(VGG, 100, dataset_unnormalized, validate_unnormalized, testset_unnormalized, \"vgg-u-M.pth\")\n",
        "\n",
        "    DN = DenseNet121().cuda()\n",
        "    training(DN, 100,  dataset_normalized, validate_normalized, testset_normalized, \"DN-n-M.pth\")\n",
        "    VGG = VGG16().cuda()\n",
        "    training(VGG, 100, dataset_normalized, validate_normalized, testset_normalized, \"vgg-n-M.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVpWTVjULjXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}